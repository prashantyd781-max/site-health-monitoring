{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üèóÔ∏è YOLOv8 Segmentation Training - Kaggle\n",
        "\n",
        "Train a YOLOv8 segmentation model to detect and segment:\n",
        "- **Exposed Rebar** üî©\n",
        "- **Spalling** üß±\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ö° Quick Start Guide\n",
        "\n",
        "### Before You Begin:\n",
        "1. **Enable GPU**: Settings ‚Üí Accelerator ‚Üí GPU T4 x2 (or P100)\n",
        "2. **Enable Internet**: Settings ‚Üí Internet ‚Üí ON\n",
        "3. **Get Roboflow API Key**: Go to https://app.roboflow.com/settings/api\n",
        "\n",
        "### Run the Notebook:\n",
        "- **Easy Mode**: Run ‚Üí Run All (requires API key in Cell 6)\n",
        "- **Step by Step**: Run each cell with Shift + Enter\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Requirements\n",
        "- ‚úÖ Kaggle with GPU enabled (T4 x2 or P100 recommended)\n",
        "- ‚úÖ Internet enabled (for dataset download)\n",
        "- ‚úÖ Roboflow API Key (free account - get it at https://app.roboflow.com/settings/api)\n",
        "- ‚úÖ ~2-4 hours training time\n",
        "\n",
        "## üéØ Training Pipeline\n",
        "1. ‚úì Check GPU availability\n",
        "2. ‚úì Install dependencies (Ultralytics + Roboflow)\n",
        "3. ‚ö†Ô∏è **Download dataset** (YOU NEED API KEY HERE!)\n",
        "4. ‚úì Configure training parameters\n",
        "5. ‚úì Train YOLOv8 segmentation model\n",
        "6. ‚úì Visualize results & metrics\n",
        "7. ‚úì Test on sample images\n",
        "8. ‚úì Save trained model to Kaggle output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1Ô∏è‚É£ Check GPU Availability\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# Check GPU\n",
        "print(\"üîç Checking GPU availability...\\n\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "    device = '0'  # Use first GPU\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No GPU detected! Training will be slow on CPU.\")\n",
        "    print(\"üí° Enable GPU: Settings ‚Üí Accelerator ‚Üí GPU T4 x2\")\n",
        "    device = 'cpu'\n",
        "\n",
        "print(f\"\\n‚úÖ Training device: {device}\")\n",
        "print(f\"üìÇ Working directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2Ô∏è‚É£ Install Dependencies\n",
        "\n",
        "This cell will:\n",
        "1. Fix NumPy compatibility (downgrade from 2.x to 1.x if needed)\n",
        "2. Install Ultralytics (YOLOv8)\n",
        "3. Install Roboflow (for dataset download)\n",
        "\n",
        "**Note:** Kaggle might have different package versions than Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üì¶ Installing dependencies...\\n\")\n",
        "\n",
        "# Fix NumPy compatibility issue - AGGRESSIVE FIX\n",
        "print(\"üîß Step 1: Fixing NumPy compatibility...\")\n",
        "print(\"   Uninstalling NumPy 2.x...\")\n",
        "!pip uninstall numpy -y -q\n",
        "print(\"   Installing NumPy 1.x...\")\n",
        "!pip install \"numpy==1.26.4\" -q\n",
        "print(\"   ‚úÖ NumPy 1.26.4 installed\")\n",
        "\n",
        "# Install ultralytics (YOLOv8)\n",
        "print(\"\\nüîß Step 2: Installing Ultralytics (YOLOv8)...\")\n",
        "!pip install ultralytics -q\n",
        "\n",
        "# Install roboflow\n",
        "print(\"üîß Step 3: Installing Roboflow...\")\n",
        "!pip install roboflow -q\n",
        "\n",
        "print(\"\\n‚úÖ All dependencies installed successfully!\")\n",
        "print(\"‚úÖ NumPy version fixed for compatibility\")\n",
        "\n",
        "# Verify installations\n",
        "import numpy as np\n",
        "print(f\"\\nüìä Installed versions:\")\n",
        "print(f\"   NumPy: {np.__version__}\")\n",
        "try:\n",
        "    from ultralytics import YOLO\n",
        "    print(f\"   Ultralytics: ‚úì Installed\")\n",
        "except:\n",
        "    print(f\"   Ultralytics: ‚úó Failed\")\n",
        "try:\n",
        "    from roboflow import Roboflow\n",
        "    print(f\"   Roboflow: ‚úì Installed\")\n",
        "except:\n",
        "    print(f\"   Roboflow: ‚úó Failed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3Ô∏è‚É£ Download Dataset from Roboflow\n",
        "\n",
        "### ‚ö†Ô∏è IMPORTANT: Get Your Roboflow API Key\n",
        "\n",
        "**Before running this cell, you MUST:**\n",
        "\n",
        "1. Go to: https://app.roboflow.com/settings/api\n",
        "2. Log in or create a free account\n",
        "3. Copy your **Private API Key**\n",
        "4. Paste it in the cell below, replacing `\"YOUR_API_KEY_HERE\"`\n",
        "\n",
        "**Example:**\n",
        "```python\n",
        "ROBOFLOW_API_KEY = \"abc123XYZ456\"  # ‚Üê Replace with YOUR actual key\n",
        "```\n",
        "\n",
        "‚ö†Ô∏è **Do NOT run this cell until you replace the API key!**\n",
        "\n",
        "‚ö†Ô∏è **Make sure Internet is enabled**: Settings ‚Üí Internet ‚Üí ON\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from roboflow import Roboflow\n",
        "\n",
        "# üîë YOUR ROBOFLOW API KEY\n",
        "# Get it from: https://app.roboflow.com/settings/api\n",
        "ROBOFLOW_API_KEY = \"orloumjlWtpPXoxK5bFa\"  # ‚úÖ API key configured!\n",
        "\n",
        "# Validate API key\n",
        "if ROBOFLOW_API_KEY == \"YOUR_API_KEY_HERE\":\n",
        "    print(\"‚ùå ERROR: You need to replace 'YOUR_API_KEY_HERE' with your actual Roboflow API key!\")\n",
        "    print(\"\\nüìã Steps to get your API key:\")\n",
        "    print(\"   1. Go to: https://app.roboflow.com/settings/api\")\n",
        "    print(\"   2. Log in to your Roboflow account (or create one - it's free!)\")\n",
        "    print(\"   3. Copy your 'Private API Key'\")\n",
        "    print(\"   4. Paste it above, replacing 'YOUR_API_KEY_HERE'\")\n",
        "    print(\"   5. Re-run this cell\")\n",
        "    print(\"\\nüí° Example: ROBOFLOW_API_KEY = \\\"abc123XYZ456def789\\\"\")\n",
        "    raise ValueError(\"API key not configured\")\n",
        "\n",
        "# Initialize Roboflow\n",
        "print(\"üîë Initializing Roboflow with your API key...\")\n",
        "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
        "\n",
        "# Download the Spalling and Exposed Rebar dataset\n",
        "print(\"üì¶ Downloading dataset from Roboflow...\")\n",
        "print(\"   Workspace: labelling-9tvkx\")\n",
        "print(\"   Project: spalling-and-exposed-rebar-ttsjj\")\n",
        "print(\"   Version: 1\")\n",
        "print(\"\\n‚è≥ This may take a few minutes...\")\n",
        "\n",
        "project = rf.workspace(\"labelling-9tvkx\").project(\"spalling-and-exposed-rebar-ttsjj\")\n",
        "dataset = project.version(1).download(\"yolov8\")\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset downloaded successfully!\")\n",
        "print(f\"üìÇ Location: {dataset.location}\")\n",
        "dataset_path = dataset.location\n",
        "\n",
        "# Show dataset structure\n",
        "import os\n",
        "print(f\"\\nüìä Dataset Structure:\")\n",
        "for folder in ['train', 'valid', 'test']:\n",
        "    folder_path = os.path.join(dataset.location, folder, 'images')\n",
        "    if os.path.exists(folder_path):\n",
        "        count = len([f for f in os.listdir(folder_path) if f.endswith('.jpg')])\n",
        "        print(f\"   {folder:6s}: {count} images\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üí° Troubleshooting - Common Issues\n",
        "\n",
        "### üî• **KERNEL DYING / CRASHING (Most Common!)**\n",
        "\n",
        "#### ‚ùå Error: \"Kernel is dying\" or kernel restarts during training\n",
        "**Cause:** Out of Memory (OOM) - GPU ran out of memory!\n",
        "\n",
        "**Solution:** Reduce batch size in Cell 10/11:\n",
        "1. Go to the training configuration cell\n",
        "2. Change: `'batch': 8` ‚Üí `'batch': 4`\n",
        "3. If still crashing: `'batch': 4` ‚Üí `'batch': 2`\n",
        "4. Re-run from Cell 10 onwards\n",
        "\n",
        "**Quick fix:**\n",
        "```python\n",
        "CONFIG['batch'] = 4  # Add this line before training\n",
        "```\n",
        "\n",
        "**Note:** Smaller batch = slower training but more stable\n",
        "\n",
        "---\n",
        "\n",
        "### üìã Installation Issues (Cell 4)\n",
        "\n",
        "#### ‚ùå Error: \"numpy.core.multiarray failed to import\" or \"NumPy 2.x incompatibility\"\n",
        "**Solution:** This is already fixed in Cell 4!\n",
        "- Re-run **Cell 4** to downgrade NumPy to version 1.x\n",
        "- You should see \"NumPy: 1.x.x\" in the output (not 2.x.x)\n",
        "\n",
        "---\n",
        "\n",
        "### üì¶ Dataset Download Issues (Cell 6)\n",
        "\n",
        "#### ‚ùå Error: \"This API key does not exist\"\n",
        "**Solution:** You didn't replace `YOUR_API_KEY_HERE`!\n",
        "- Go back to Cell 6\n",
        "- Replace with your real key from https://app.roboflow.com/settings/api\n",
        "- Re-run Cell 6\n",
        "\n",
        "#### ‚ùå Error: \"No internet connection\" or \"Connection timeout\"\n",
        "**Solution:** Internet is not enabled!\n",
        "- Go to: Settings ‚Üí Internet ‚Üí Turn ON\n",
        "- Re-run Cell 6\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ If Everything Works:\n",
        "You should see:\n",
        "- Cell 4: \"NumPy: 1.x.x\" and all packages installed ‚úì\n",
        "- Cell 6: \"‚úÖ Dataset downloaded successfully!\" with image counts\n",
        "- Cell 9: GPU memory status with recommendations\n",
        "\n",
        "üëá **Continue to the next cell if you see the success messages above!**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4Ô∏è‚É£ Check GPU Memory (Important!)\n",
        "\n",
        "Before training, let's check available GPU memory to avoid crashes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"üîç GPU Memory Status:\\n\")\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
        "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "        print(f\"   Total Memory: {gpu_memory:.2f} GB\")\n",
        "        \n",
        "        # Clear any cached memory\n",
        "        torch.cuda.empty_cache()\n",
        "        allocated = torch.cuda.memory_allocated(i) / 1024**3\n",
        "        reserved = torch.cuda.memory_reserved(i) / 1024**3\n",
        "        print(f\"   Allocated: {allocated:.2f} GB\")\n",
        "        print(f\"   Reserved: {reserved:.2f} GB\")\n",
        "        print(f\"   Free: {gpu_memory - reserved:.2f} GB\\n\")\n",
        "    \n",
        "    # Recommendations based on GPU memory\n",
        "    if gpu_memory < 16:\n",
        "        print(\"‚ö†Ô∏è  GPU has less than 16GB memory\")\n",
        "        print(\"üí° Recommended batch size: 4-8\")\n",
        "        print(\"üí° If kernel crashes, use batch=4 in next cell\\n\")\n",
        "    else:\n",
        "        print(\"‚úÖ GPU has sufficient memory\")\n",
        "        print(\"üí° You can use batch size 8-16\\n\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No GPU detected! Training will be very slow on CPU.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5Ô∏è‚É£ Configure Training Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MINIMAL TEST CONFIGURATION - Find what's breaking!\n",
        "CONFIG = {\n",
        "    'model': 'yolov8n-seg.pt',\n",
        "    'data': f'{dataset_path}/data.yaml',\n",
        "    'epochs': 2,                     # Just 2 epochs to test!\n",
        "    'imgsz': 320,                    # Very small\n",
        "    'batch': 1,                      # Single image\n",
        "    'device': device,\n",
        "    'project': '/kaggle/working/runs/segment',\n",
        "    'name': 'minimal_test',\n",
        "    'save': False,                   # Don't save anything\n",
        "    'plots': False,\n",
        "    'verbose': True,\n",
        "    'cache': False,\n",
        "    'workers': 0,                    # Critical: no multiprocessing\n",
        "    'rect': False,\n",
        "    'single_cls': False,\n",
        "    # Disable ALL augmentations\n",
        "    'hsv_h': 0.0,\n",
        "    'hsv_s': 0.0,\n",
        "    'hsv_v': 0.0,\n",
        "    'degrees': 0.0,\n",
        "    'translate': 0.0,\n",
        "    'scale': 0.0,\n",
        "    'shear': 0.0,\n",
        "    'perspective': 0.0,\n",
        "    'flipud': 0.0,\n",
        "    'fliplr': 0.0,\n",
        "    'mosaic': 0.0,\n",
        "    'mixup': 0.0,\n",
        "    'copy_paste': 0.0,\n",
        "}\n",
        "\n",
        "print(\"üß™ MINIMAL TEST CONFIGURATION\")\n",
        "print(\"=\" * 80)\n",
        "print(\"‚ö†Ô∏è  Kernel keeps dying even with workers=0!\")\n",
        "print(\"üéØ Using ABSOLUTE MINIMUM settings to isolate the problem\")\n",
        "print(\"=\" * 80)\n",
        "for key, value in CONFIG.items():\n",
        "    print(f\"   {key:20s}: {value}\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nüîç THIS TEST WILL:\")\n",
        "print(\"   1. Run for just 2 epochs (~5 minutes)\")\n",
        "print(\"   2. Use smallest possible settings\")\n",
        "print(\"   3. All augmentations disabled\")\n",
        "print(\"   4. If this fails, we'll try detection model instead\")\n",
        "print(\"\\n‚è∞ Should complete in 5-10 minutes if it works\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üîÑ ALTERNATIVE: Try Detection Model (If Segmentation Keeps Failing)\n",
        "\n",
        "If the above keeps crashing, uncomment this cell to try **object detection** instead of segmentation.\n",
        "Detection uses less memory and is more stable.\n",
        "\n",
        "```python\n",
        "# ALTERNATIVE CONFIG - DETECTION MODEL (not segmentation)\n",
        "# Uncomment this entire section if segmentation keeps failing!\n",
        "\n",
        "# CONFIG = {\n",
        "#     'model': 'yolov8n.pt',           # Detection model (NOT segmentation!)\n",
        "#     'data': f'{dataset_path}/data.yaml',\n",
        "#     'epochs': 10,\n",
        "#     'imgsz': 640,\n",
        "#     'batch': 16,                     # Can use larger batch for detection\n",
        "#     'device': device,\n",
        "#     'project': '/kaggle/working/runs/detect',  # Different output folder\n",
        "#     'name': 'spalling_detection',\n",
        "#     'plots': False,\n",
        "#     'verbose': True,\n",
        "#     'cache': False,\n",
        "#     'workers': 0,\n",
        "# }\n",
        "# \n",
        "# print(\"üîÑ TRYING DETECTION MODEL INSTEAD\")\n",
        "# print(\"   Note: This will detect objects but NOT segment them\")\n",
        "# print(\"   (Bounding boxes only, no masks)\")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6Ô∏è‚É£ Clear GPU Memory (IMPORTANT!)\n",
        "\n",
        "Before training, let's aggressively clear any cached GPU memory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "# Clear Python garbage\n",
        "gc.collect()\n",
        "\n",
        "# Clear GPU cache\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.synchronize()\n",
        "    \n",
        "    # Check memory after clearing\n",
        "    allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
        "    reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
        "    \n",
        "    print(\"üßπ GPU Memory Cleared!\")\n",
        "    print(f\"   Allocated: {allocated:.2f} GB\")\n",
        "    print(f\"   Reserved: {reserved:.2f} GB\")\n",
        "    print(\"\\n‚úÖ GPU is ready for training!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No GPU available - training on CPU will be very slow\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7Ô∏è‚É£ Initialize Model and Start Training\n",
        "\n",
        "‚è∞ **Training time: 3-4 hours** (with batch=8, imgsz=640 - Normal speed!)\n",
        "\n",
        "**üéØ THE FIX: workers=0**\n",
        "- Kernel was dying BEFORE first epoch (not during training)\n",
        "- This means it was a **data loading issue**, not memory!\n",
        "- Setting `workers=0` disables problematic multiprocessing\n",
        "\n",
        "**GPU Memory Monitor (with batch=8):**\n",
        "- ‚úÖ **8-10 GB**: Normal (plenty of headroom on T4's 15GB)\n",
        "- ‚ö†Ô∏è **> 13 GB**: Approaching limit\n",
        "- ‚ùå **> 14 GB**: Will crash\n",
        "\n",
        "**What Changed:**\n",
        "- ‚úÖ **Batch size: 8** (not 1!) - Normal training\n",
        "- ‚úÖ **Image size: 640** (not 384!) - Full quality\n",
        "- ‚úÖ **Workers: 0** - This was the actual issue!\n",
        "- ‚úÖ **3-4 hours** instead of 10-12 hours!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import time\n",
        "import traceback\n",
        "import sys\n",
        "\n",
        "print(\"\\n\" + \"üöÄ\" * 40)\n",
        "print(\"STARTING YOLOV8 SEGMENTATION TRAINING - KAGGLE\")\n",
        "print(\"üöÄ\" * 40 + \"\\n\")\n",
        "\n",
        "try:\n",
        "    # Initialize model\n",
        "    print(\"üîß Step 1: Loading YOLOv8n-seg pretrained model...\")\n",
        "    model = YOLO(CONFIG['model'])\n",
        "    print(\"‚úÖ Model loaded successfully!\\n\")\n",
        "    \n",
        "    # Verify dataset\n",
        "    print(\"üîß Step 2: Verifying dataset...\")\n",
        "    print(f\"   Dataset path: {CONFIG['data']}\")\n",
        "    import os\n",
        "    if os.path.exists(CONFIG['data']):\n",
        "        print(\"‚úÖ Dataset file exists!\\n\")\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"Dataset not found: {CONFIG['data']}\")\n",
        "    \n",
        "    # Start training\n",
        "    print(\"üèãÔ∏è  Step 3: Starting training...\\n\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"üìÇ Results will be saved to: {CONFIG['project']}/{CONFIG['name']}\")\n",
        "    print(f\"üíæ Model checkpoints: /kaggle/working/ (saved as output)\")\n",
        "    print(\"=\" * 80 + \"\\n\")\n",
        "    \n",
        "    print(\"‚è∞ Training started at:\", time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
        "    print(\"\\nüìä Watch the GPU_mem column below:\")\n",
        "    print(\"   Should stay around 2-4 GB with batch=1\")\n",
        "    print(\"   If it goes > 10 GB, it might crash\\n\")\n",
        "    print(\"=\" * 80 + \"\\n\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Train with error catching\n",
        "    results = model.train(**CONFIG)\n",
        "    \n",
        "    training_time = time.time() - start_time\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üéâ TRAINING COMPLETED SUCCESSFULLY! üéâ\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"\\n‚è±Ô∏è  Total training time: {training_time/3600:.2f} hours\")\n",
        "    print(f\"üìÇ Model saved to: {CONFIG['project']}/{CONFIG['name']}/weights/best.pt\")\n",
        "    print(f\"üíæ All results saved to: /kaggle/working/runs/segment/{CONFIG['name']}/\")\n",
        "    print(\"\\nüí° Files in /kaggle/working/ are automatically saved as notebook output!\")\n",
        "    \n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n‚ö†Ô∏è  Training interrupted by user (Ctrl+C)\")\n",
        "    print(\"üíæ Partial results may be saved in:\", CONFIG['project'])\n",
        "    \n",
        "except RuntimeError as e:\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"‚ùå RUNTIME ERROR DETECTED!\")\n",
        "    print(\"=\" * 80)\n",
        "    error_msg = str(e)\n",
        "    print(f\"\\nError message: {error_msg}\\n\")\n",
        "    \n",
        "    # Check if it's OOM\n",
        "    if \"out of memory\" in error_msg.lower() or \"oom\" in error_msg.lower():\n",
        "        print(\"üî• This IS a GPU Out of Memory error!\")\n",
        "        print(\"\\nüí° Solutions:\")\n",
        "        print(\"   1. Reduce batch size further (already at minimum!)\")\n",
        "        print(\"   2. Reduce image size: CONFIG['imgsz'] = 320\")\n",
        "        print(\"   3. Try detection instead: 'yolov8n.pt'\")\n",
        "    else:\n",
        "        print(\"ü§î This is NOT an OOM error - it's something else!\")\n",
        "        print(\"\\nüí° Possible causes:\")\n",
        "        print(\"   - Dataset loading issue\")\n",
        "        print(\"   - Corrupted images\")\n",
        "        print(\"   - PyTorch/CUDA compatibility\")\n",
        "        print(\"   - Augmentation bug\")\n",
        "    \n",
        "    print(f\"\\nFull traceback:\")\n",
        "    traceback.print_exc()\n",
        "    \n",
        "except Exception as e:\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"‚ùå UNEXPECTED ERROR!\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"\\nError type: {type(e).__name__}\")\n",
        "    print(f\"Error message: {str(e)}\\n\")\n",
        "    print(f\"Full traceback:\")\n",
        "    traceback.print_exc()\n",
        "    \n",
        "    print(\"\\nüí° This error information will help debug the issue!\")\n",
        "    print(\"   Please share this error message for help.\")\n",
        "    \n",
        "finally:\n",
        "    # Cleanup\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"\\nüßπ GPU cache cleared\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6Ô∏è‚É£ Visualize Training Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "import glob\n",
        "\n",
        "results_dir = f\"{CONFIG['project']}/{CONFIG['name']}\"\n",
        "\n",
        "print(\"üìà Training Results Visualizations:\\n\")\n",
        "\n",
        "# Display results plot\n",
        "if os.path.exists(f\"{results_dir}/results.png\"):\n",
        "    print(\"üìä Training Curves:\")\n",
        "    display(Image(filename=f\"{results_dir}/results.png\"))\n",
        "\n",
        "# Display confusion matrix\n",
        "if os.path.exists(f\"{results_dir}/confusion_matrix_normalized.png\"):\n",
        "    print(\"\\nüéØ Confusion Matrix:\")\n",
        "    display(Image(filename=f\"{results_dir}/confusion_matrix_normalized.png\"))\n",
        "\n",
        "# Display validation predictions\n",
        "val_images = glob.glob(f\"{results_dir}/val_batch*_pred.jpg\")\n",
        "if val_images:\n",
        "    print(\"\\nüîç Validation Predictions:\")\n",
        "    for img_path in val_images[:3]:  # Show first 3 batches\n",
        "        display(Image(filename=img_path, width=800))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7Ô∏è‚É£ Evaluate Model Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load results CSV\n",
        "results_csv = f\"{results_dir}/results.csv\"\n",
        "if os.path.exists(results_csv):\n",
        "    df = pd.read_csv(results_csv)\n",
        "    df.columns = df.columns.str.strip()\n",
        "    \n",
        "    print(\"üìä Final Training Metrics:\\n\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Get last epoch metrics\n",
        "    last_epoch = df.iloc[-1]\n",
        "    \n",
        "    metrics = [\n",
        "        ('Box Precision', 'metrics/precision(B)'),\n",
        "        ('Box Recall', 'metrics/recall(B)'),\n",
        "        ('Box mAP50', 'metrics/mAP50(B)'),\n",
        "        ('Box mAP50-95', 'metrics/mAP50-95(B)'),\n",
        "        ('Mask Precision', 'metrics/precision(M)'),\n",
        "        ('Mask Recall', 'metrics/recall(M)'),\n",
        "        ('Mask mAP50', 'metrics/mAP50(M)'),\n",
        "        ('Mask mAP50-95', 'metrics/mAP50-95(M)'),\n",
        "    ]\n",
        "    \n",
        "    for name, col in metrics:\n",
        "        if col in df.columns:\n",
        "            print(f\"{name:25s}: {last_epoch[col]:.4f}\")\n",
        "    \n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Show last 10 epochs\n",
        "    print(\"\\nüìâ Last 10 Epochs Performance:\")\n",
        "    print(df[['epoch', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', \n",
        "              'metrics/mAP50(M)', 'metrics/mAP50-95(M)']].tail(10).to_string(index=False))\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Results CSV not found\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 8Ô∏è‚É£ Test Model on Sample Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the best trained model\n",
        "best_model_path = f\"{results_dir}/weights/best.pt\"\n",
        "model = YOLO(best_model_path)\n",
        "\n",
        "# Get some test images\n",
        "test_images = glob.glob(f\"{dataset_path}/test/images/*.jpg\")[:5]\n",
        "\n",
        "if test_images:\n",
        "    print(\"üî¨ Running inference on test images...\\n\")\n",
        "    \n",
        "    for img_path in test_images:\n",
        "        # Run inference\n",
        "        results = model(img_path)\n",
        "        \n",
        "        # Plot results\n",
        "        for r in results:\n",
        "            im_array = r.plot()\n",
        "            \n",
        "            # Display\n",
        "            from PIL import Image as PILImage\n",
        "            import matplotlib.pyplot as plt\n",
        "            \n",
        "            plt.figure(figsize=(12, 8))\n",
        "            plt.imshow(im_array[..., ::-1])\n",
        "            plt.axis('off')\n",
        "            plt.title(f\"Prediction: {os.path.basename(img_path)}\")\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            \n",
        "            # Print detections\n",
        "            if len(r.boxes) > 0:\n",
        "                print(f\"   Detected {len(r.boxes)} objects in {os.path.basename(img_path)}\")\n",
        "                for i, box in enumerate(r.boxes):\n",
        "                    cls_id = int(box.cls[0])\n",
        "                    conf = float(box.conf[0])\n",
        "                    cls_name = model.names[cls_id]\n",
        "                    print(f\"      {i+1}. {cls_name}: {conf:.3f}\")\n",
        "            else:\n",
        "                print(f\"   No objects detected in {os.path.basename(img_path)}\")\n",
        "            print()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No test images found\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# The model is already in /kaggle/working/runs/ so it will be saved\n",
        "# Let's also copy the best model to the working directory root for easy access\n",
        "best_model = f\"{results_dir}/weights/best.pt\"\n",
        "last_model = f\"{results_dir}/weights/last.pt\"\n",
        "\n",
        "if os.path.exists(best_model):\n",
        "    shutil.copy(best_model, \"/kaggle/working/best.pt\")\n",
        "    print(f\"‚úÖ Copied best model to: /kaggle/working/best.pt\")\n",
        "    print(f\"   File size: {os.path.getsize('/kaggle/working/best.pt') / 1024**2:.2f} MB\")\n",
        "\n",
        "if os.path.exists(last_model):\n",
        "    shutil.copy(last_model, \"/kaggle/working/last.pt\")\n",
        "    print(f\"‚úÖ Copied last model to: /kaggle/working/last.pt\")\n",
        "    print(f\"   File size: {os.path.getsize('/kaggle/working/last.pt') / 1024**2:.2f} MB\")\n",
        "\n",
        "# Create a results summary\n",
        "print(f\"\\nüìÇ All Training Results:\")\n",
        "print(f\"   Model weights: {results_dir}/weights/\")\n",
        "print(f\"   Training curves: {results_dir}/results.png\")\n",
        "print(f\"   Confusion matrix: {results_dir}/confusion_matrix_normalized.png\")\n",
        "print(f\"   Results CSV: {results_dir}/results.csv\")\n",
        "print(f\"\\nüíæ To download:\")\n",
        "print(f\"   1. Click 'Output' tab at the top\")\n",
        "print(f\"   2. Find your files in the output section\")\n",
        "print(f\"   3. Click download button\")\n",
        "print(f\"\\nüìÅ Working directory contents:\")\n",
        "!ls -lh /kaggle/working/*.pt 2>/dev/null || echo \"   (model files listed above)\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üîü Export Model (Optional)\n",
        "\n",
        "Export to ONNX format for deployment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export to ONNX format (for broader deployment)\n",
        "print(\"üîÑ Exporting model to ONNX format...\\n\")\n",
        "\n",
        "model = YOLO(best_model_path)\n",
        "export_path = model.export(format='onnx')\n",
        "\n",
        "# Copy to working directory\n",
        "if os.path.exists(export_path):\n",
        "    shutil.copy(export_path, \"/kaggle/working/best.onnx\")\n",
        "    print(f\"\\n‚úÖ Model exported to: /kaggle/working/best.onnx\")\n",
        "    print(f\"   File size: {os.path.getsize('/kaggle/working/best.onnx') / 1024**2:.2f} MB\")\n",
        "\n",
        "print(\"\\nüì¶ Available export formats:\")\n",
        "print(\"   - PyTorch (.pt) ‚úì\")\n",
        "print(\"   - ONNX (.onnx) ‚úì\")\n",
        "print(\"   - TensorRT (.engine)\")\n",
        "print(\"   - CoreML (.mlmodel)\")\n",
        "print(\"   - TFLite (.tflite)\")\n",
        "print(\"\\nüí° To export to other formats, use: model.export(format='<format>')\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üìù Summary\n",
        "\n",
        "### Training Complete! üéâ\n",
        "\n",
        "Your YOLOv8 segmentation model has been trained to detect and segment:\n",
        "- **Exposed Rebar** üî©\n",
        "- **Spalling** üß±\n",
        "\n",
        "### üìÇ Output Files (in Kaggle Output):\n",
        "- `best.pt` - Best model weights (lowest validation loss)\n",
        "- `last.pt` - Last epoch checkpoint\n",
        "- `best.onnx` - ONNX export (optional)\n",
        "- `runs/segment/spalling_rebar_training/` - All training results\n",
        "\n",
        "### üíæ How to Download from Kaggle:\n",
        "1. Click the **\"Output\"** tab at the top of the page\n",
        "2. Find your files in the output section\n",
        "3. Click the **download** button next to each file\n",
        "4. Or download the entire output as a zip\n",
        "\n",
        "### üöÄ Next Steps:\n",
        "1. Download the `best.pt` model\n",
        "2. Use it for inference on new images\n",
        "3. Deploy in your application\n",
        "4. Fine-tune with more data if needed\n",
        "\n",
        "### üíª Usage Example:\n",
        "```python\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load model\n",
        "model = YOLO('best.pt')\n",
        "\n",
        "# Run inference\n",
        "results = model('path/to/image.jpg')\n",
        "\n",
        "# Display results\n",
        "results[0].show()\n",
        "\n",
        "# Get segmentation masks\n",
        "masks = results[0].masks  # Segmentation masks\n",
        "boxes = results[0].boxes  # Bounding boxes\n",
        "```\n",
        "\n",
        "### üìä Expected Performance:\n",
        "- **Box mAP50**: ~75-85%\n",
        "- **Mask mAP50**: ~70-80%\n",
        "- **Training time**: 2-4 hours on T4 GPU\n",
        "- **Model size**: ~6MB (YOLOv8n-seg)\n",
        "\n",
        "---\n",
        "\n",
        "**Happy Segmenting! üéØ**\n",
        "\n",
        "**All your files are saved in the Output tab. Check the \"Output\" section above to download your trained model!**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
