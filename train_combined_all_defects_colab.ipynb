{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ—ï¸ Combined YOLOv8 Training - ALL Defects (Google Colab)\n",
        "\n",
        "Train **ONE unified model** to detect:\n",
        "- ğŸ”´ **Cracks** - Structural cracks\n",
        "- ğŸ§± **Spalling** - Concrete deterioration  \n",
        "- ğŸ”© **Exposed Rebar** - Visible reinforcement bars\n",
        "\n",
        "---\n",
        "\n",
        "## âš¡ Quick Start\n",
        "\n",
        "### Before You Begin:\n",
        "1. **Enable GPU**: Runtime â†’ Change runtime type â†’ T4 GPU\n",
        "2. **Get Roboflow API Key**: https://app.roboflow.com/settings/api\n",
        "3. **Update crack dataset info** in Cell 6\n",
        "\n",
        "### What This Does:\n",
        "- Downloads **2 datasets** (crack + spalling/rebar)\n",
        "- **Merges** into unified dataset\n",
        "- **Trains single model** for all 3 classes\n",
        "- **One model to detect everything!** ğŸ¯\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“‹ Classes:\n",
        "- **Class 0**: crack ğŸ”´\n",
        "- **Class 1**: spalling ğŸ§±\n",
        "- **Class 2**: exposed_rebar ğŸ”©\n",
        "\n",
        "Training time: ~3-4 hours on T4 GPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1ï¸âƒ£ Check GPU Availability\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "print(\"ğŸ” Checking GPU availability...\\n\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "    print(f\"GPU Memory: {gpu_memory:.2f} GB\")\n",
        "    device = '0'\n",
        "    \n",
        "    if gpu_memory < 15:\n",
        "        print(f\"\\nâš ï¸  GPU has {gpu_memory:.1f}GB\")\n",
        "        print(\"ğŸ’¡ Use batch size 4\")\n",
        "    else:\n",
        "        print(f\"\\nâœ… GPU has {gpu_memory:.1f}GB\")\n",
        "        print(\"ğŸ’¡ Can use batch size 8\")\n",
        "else:\n",
        "    print(\"\\nâš ï¸ No GPU detected!\")\n",
        "    print(\"ğŸ’¡ Enable GPU: Runtime â†’ Change runtime type â†’ T4 GPU\")\n",
        "    device = 'cpu'\n",
        "\n",
        "print(f\"\\nâœ… Device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2ï¸âƒ£ Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ğŸ“¦ Installing dependencies...\\n\")\n",
        "\n",
        "!pip install ultralytics roboflow pyyaml -q\n",
        "\n",
        "print(\"\\nâœ… All dependencies installed!\")\n",
        "\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from roboflow import Roboflow\n",
        "import yaml\n",
        "\n",
        "print(f\"\\nğŸ“Š Versions:\")\n",
        "print(f\"   NumPy: {np.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3ï¸âƒ£ Configure API Key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ”‘ YOUR ROBOFLOW API KEY\n",
        "ROBOFLOW_API_KEY = \"orloumjlWtpPXoxK5bFa\"  # âœ… Configured\n",
        "\n",
        "if ROBOFLOW_API_KEY == \"YOUR_API_KEY_HERE\":\n",
        "    print(\"âŒ ERROR: Replace with your API key!\")\n",
        "    raise ValueError(\"API key not configured\")\n",
        "\n",
        "print(\"âœ… API key set\")\n",
        "print(\"ğŸ”‘ Initializing Roboflow...\")\n",
        "\n",
        "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
        "print(\"âœ… Roboflow ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4ï¸âƒ£ Download Datasets\n",
        "\n",
        "âš ï¸ **IMPORTANT**: Update CRACK_WORKSPACE and CRACK_PROJECT with your crack detection dataset info!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ğŸ“¦ DOWNLOADING DATASETS\\n\" + \"=\" * 80)\n",
        "\n",
        "# Dataset 1: Spalling & Exposed Rebar\n",
        "print(\"\\nğŸ“¥ 1/2: Downloading Spalling & Exposed Rebar...\")\n",
        "try:\n",
        "    project1 = rf.workspace(\"labelling-9tvkx\").project(\"spalling-and-exposed-rebar-ttsjj\")\n",
        "    dataset1 = project1.version(1).download(\"yolov8\", location=\"/content/dataset_spalling\")\n",
        "    print(f\"âœ… Downloaded: {dataset1.location}\")\n",
        "    dataset1_location = dataset1.location\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed: {e}\")\n",
        "    dataset1_location = None\n",
        "\n",
        "# Dataset 2: Crack Detection  \n",
        "print(\"\\nğŸ“¥ 2/2: Downloading Crack Detection...\")\n",
        "print(\"âš ï¸  UPDATE THESE VALUES WITH YOUR CRACK DATASET INFO:\")\n",
        "\n",
        "# âš ï¸ UPDATE THESE WITH YOUR ACTUAL CRACK DATASET INFO FROM ROBOFLOW\n",
        "CRACK_WORKSPACE = \"your-workspace-name\"  # â† UPDATE THIS!\n",
        "CRACK_PROJECT = \"your-crack-project\"      # â† UPDATE THIS!\n",
        "CRACK_VERSION = 1                         # â† UPDATE IF NEEDED\n",
        "\n",
        "try:\n",
        "    project2 = rf.workspace(CRACK_WORKSPACE).project(CRACK_PROJECT)\n",
        "    dataset2 = project2.version(CRACK_VERSION).download(\"yolov8\", location=\"/content/dataset_crack\")\n",
        "    print(f\"âœ… Downloaded: {dataset2.location}\")\n",
        "    dataset2_location = dataset2.location\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed: {e}\")\n",
        "    print(\"\\nğŸ’¡ To find your dataset info:\")\n",
        "    print(\"   1. Go to https://app.roboflow.com/\")\n",
        "    print(\"   2. Open your crack detection project\")\n",
        "    print(\"   3. Look at the URL: app.roboflow.com/WORKSPACE/PROJECT\")\n",
        "    print(\"   4. Update CRACK_WORKSPACE and CRACK_PROJECT above\")\n",
        "    print(\"\\nâš ï¸  Continuing with spalling/rebar only...\")\n",
        "    dataset2_location = None\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5ï¸âƒ£ Merge Datasets\n",
        "\n",
        "Combining both datasets with proper class remapping.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "print(\"ğŸ”„ MERGING DATASETS\\n\" + \"=\" * 80)\n",
        "\n",
        "# Create combined dataset structure\n",
        "combined_dir = Path(\"/content/combined_dataset\")\n",
        "combined_dir.mkdir(exist_ok=True)\n",
        "\n",
        "for split in ['train', 'valid', 'test']:\n",
        "    (combined_dir / split / 'images').mkdir(parents=True, exist_ok=True)\n",
        "    (combined_dir / split / 'labels').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"âœ… Created structure\\n\")\n",
        "\n",
        "# Class mapping:\n",
        "# Dataset 1 (Spalling/Rebar): 0=spalling, 1=exposed_rebar\n",
        "# Dataset 2 (Cracks): 0=crack\n",
        "# Combined: 0=crack, 1=spalling, 2=exposed_rebar\n",
        "\n",
        "def merge_dataset(src_path, prefix, class_remap):\n",
        "    \"\"\"Copy images and remap labels\"\"\"\n",
        "    counts = {'train': 0, 'valid': 0, 'test': 0}\n",
        "    \n",
        "    for split in ['train', 'valid', 'test']:\n",
        "        src_img = Path(src_path) / split / 'images'\n",
        "        src_lbl = Path(src_path) / split / 'labels'\n",
        "        \n",
        "        if not src_img.exists():\n",
        "            continue\n",
        "        \n",
        "        dst_img = combined_dir / split / 'images'\n",
        "        dst_lbl = combined_dir / split / 'labels'\n",
        "        \n",
        "        # Copy each image\n",
        "        for img_file in src_img.glob('*.*'):\n",
        "            new_name = f\"{prefix}_{img_file.name}\"\n",
        "            shutil.copy(img_file, dst_img / new_name)\n",
        "            counts[split] += 1\n",
        "            \n",
        "            # Copy and remap label\n",
        "            lbl_file = src_lbl / f\"{img_file.stem}.txt\"\n",
        "            if lbl_file.exists():\n",
        "                with open(lbl_file, 'r') as f:\n",
        "                    lines = f.readlines()\n",
        "                \n",
        "                with open(dst_lbl / f\"{prefix}_{img_file.stem}.txt\", 'w') as f:\n",
        "                    for line in lines:\n",
        "                        parts = line.strip().split()\n",
        "                        if parts:\n",
        "                            old_id = int(parts[0])\n",
        "                            new_id = class_remap.get(old_id, old_id)\n",
        "                            parts[0] = str(new_id)\n",
        "                            f.write(' '.join(parts) + '\\n')\n",
        "    \n",
        "    return counts\n",
        "\n",
        "# Merge dataset 1 (Spalling/Rebar)\n",
        "if dataset1_location:\n",
        "    print(\"ğŸ“ Merging Spalling & Rebar dataset...\")\n",
        "    # Remap: 0â†’1 (spalling), 1â†’2 (exposed_rebar)\n",
        "    counts1 = merge_dataset(dataset1_location, 'sp', {0: 1, 1: 2})\n",
        "    print(f\"   Train: {counts1['train']}, Valid: {counts1['valid']}, Test: {counts1['test']}\")\n",
        "else:\n",
        "    counts1 = {'train': 0, 'valid': 0, 'test': 0}\n",
        "    print(\"âš ï¸  Spalling dataset not available\")\n",
        "\n",
        "# Merge dataset 2 (Cracks)\n",
        "if dataset2_location:\n",
        "    print(\"\\nğŸ“ Merging Crack dataset...\")\n",
        "    # Keep: 0â†’0 (crack)\n",
        "    counts2 = merge_dataset(dataset2_location, 'cr', {0: 0})\n",
        "    print(f\"   Train: {counts2['train']}, Valid: {counts2['valid']}, Test: {counts2['test']}\")\n",
        "else:\n",
        "    counts2 = {'train': 0, 'valid': 0, 'test': 0}\n",
        "    print(\"\\nâš ï¸  Crack dataset not available\")\n",
        "\n",
        "# Create data.yaml\n",
        "data_config = {\n",
        "    'path': str(combined_dir),\n",
        "    'train': 'train/images',\n",
        "    'val': 'valid/images',\n",
        "    'test': 'test/images',\n",
        "    'nc': 3,\n",
        "    'names': ['crack', 'spalling', 'exposed_rebar']\n",
        "}\n",
        "\n",
        "with open(combined_dir / 'data.yaml', 'w') as f:\n",
        "    yaml.dump(data_config, f)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"âœ… MERGING COMPLETE!\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nğŸ“Š Combined Dataset:\")\n",
        "print(f\"   Train:  {counts1['train'] + counts2['train']} images\")\n",
        "print(f\"   Valid:  {counts1['valid'] + counts2['valid']} images\")\n",
        "print(f\"   Test:   {counts1['test'] + counts2['test']} images\")\n",
        "print(f\"\\nğŸ¯ Classes:\")\n",
        "print(f\"   0: crack ğŸ”´\")\n",
        "print(f\"   1: spalling ğŸ§±\")\n",
        "print(f\"   2: exposed_rebar ğŸ”©\")\n",
        "print(f\"\\nğŸ“‚ Location: {combined_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CONFIG = {\n",
        "    'model': 'yolov8n.pt',\n",
        "    'data': str(combined_dir / 'data.yaml'),\n",
        "    'epochs': 50,\n",
        "    'imgsz': 512,\n",
        "    'batch': 4,\n",
        "    'device': device,\n",
        "    'project': '/content/runs/detect',\n",
        "    'name': 'combined_all_defects',\n",
        "    'workers': 0,\n",
        "    'cache': False,\n",
        "    'patience': 10,\n",
        "    'optimizer': 'SGD',\n",
        "    'lr0': 0.01,\n",
        "    'amp': True,\n",
        "    'plots': True,\n",
        "    'verbose': True,\n",
        "}\n",
        "\n",
        "print(\"âš™ï¸  COMBINED MODEL CONFIGURATION\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nğŸ“Š Settings:\")\n",
        "print(f\"   Model:      {CONFIG['model']}\")\n",
        "print(f\"   Epochs:     {CONFIG['epochs']}\")\n",
        "print(f\"   Image Size: {CONFIG['imgsz']}\")\n",
        "print(f\"   Batch:      {CONFIG['batch']}\")\n",
        "print(f\"   Device:     {CONFIG['device']}\")\n",
        "print(f\"\\nğŸ¯ Detecting 3 classes:\")\n",
        "print(f\"   0: crack ğŸ”´\")\n",
        "print(f\"   1: spalling ğŸ§±\")\n",
        "print(f\"   2: exposed_rebar ğŸ”©\")\n",
        "print(f\"\\nğŸ“‚ Output: {CONFIG['project']}/{CONFIG['name']}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    est = CONFIG['epochs'] * 2\n",
        "    print(f\"\\nâ° Estimated: ~{est} min ({est/60:.1f} hours)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7ï¸âƒ£ Train Combined Model\n",
        "\n",
        "Training ONE model for ALL 3 defect types!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import traceback\n",
        "import gc\n",
        "\n",
        "# Clear GPU\n",
        "print(\"ğŸ§¹ Clearing GPU...\")\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.synchronize()\n",
        "    print(\"âœ… GPU cleared\\n\")\n",
        "\n",
        "print(\"\\n\" + \"ğŸš€\" * 40)\n",
        "print(\"TRAINING COMBINED MODEL - ALL DEFECTS\")\n",
        "print(\"ğŸš€\" * 40 + \"\\n\")\n",
        "\n",
        "try:\n",
        "    print(\"ğŸ”§ Loading YOLOv8...\")\n",
        "    model = YOLO(CONFIG['model'])\n",
        "    print(\"âœ… Model loaded\\n\")\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        mem = torch.cuda.memory_allocated(0) / 1024**3\n",
        "        print(f\"ğŸ’¾ GPU: {mem:.2f} GB\\n\")\n",
        "    \n",
        "    print(\"ğŸ‹ï¸  Starting training...\\n\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"ğŸ“‚ Results: {CONFIG['project']}/{CONFIG['name']}\")\n",
        "    print(\"=\" * 80 + \"\\n\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Train\n",
        "    results = model.train(**CONFIG)\n",
        "    \n",
        "    training_time = time.time() - start_time\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"ğŸ‰ TRAINING COMPLETED! ğŸ‰\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"\\nâ±ï¸  Time: {training_time/3600:.2f} hours\")\n",
        "    print(f\"ğŸ“‚ Model: {CONFIG['project']}/{CONFIG['name']}/weights/best.pt\")\n",
        "    print(\"\\nâœ… Your model now detects:\")\n",
        "    print(\"   â€¢ Cracks ğŸ”´\")\n",
        "    print(\"   â€¢ Spalling ğŸ§±\")\n",
        "    print(\"   â€¢ Exposed Rebar ğŸ”©\")\n",
        "    print(\"\\nğŸ’¡ All in ONE model!\")\n",
        "    \n",
        "except RuntimeError as e:\n",
        "    print(\"\\nâŒ RUNTIME ERROR!\")\n",
        "    if \"out of memory\" in str(e).lower():\n",
        "        print(\"ğŸ”¥ GPU OOM!\")\n",
        "        print(\"\\nğŸ’¡ Reduce batch to 2 or imgsz to 416\")\n",
        "    traceback.print_exc()\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ ERROR: {type(e).__name__}\")\n",
        "    print(str(e))\n",
        "    traceback.print_exc()\n",
        "    \n",
        "finally:\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"\\nğŸ§¹ GPU cleared\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 8ï¸âƒ£ Save & Download Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "results_dir = f\"{CONFIG['project']}/{CONFIG['name']}\"\n",
        "best_model = f\"{results_dir}/weights/best.pt\"\n",
        "\n",
        "if os.path.exists(best_model):\n",
        "    # Copy to content root for easy access\n",
        "    shutil.copy(best_model, \"/content/combined_all_defects_best.pt\")\n",
        "    size = os.path.getsize('/content/combined_all_defects_best.pt') / 1024**2\n",
        "    \n",
        "    print(\"ğŸ’¾ COMBINED MODEL SAVED!\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"âœ… File: /content/combined_all_defects_best.pt\")\n",
        "    print(f\"ğŸ“Š Size: {size:.2f} MB\")\n",
        "    print(\"\\nğŸ¯ Detects 3 classes:\")\n",
        "    print(\"   Class 0: crack ğŸ”´\")\n",
        "    print(\"   Class 1: spalling ğŸ§±\")\n",
        "    print(\"   Class 2: exposed_rebar ğŸ”©\")\n",
        "    print(\"\\nğŸ“¥ Download the model:\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Download the model\n",
        "    files.download('/content/combined_all_defects_best.pt')\n",
        "    print(\"\\nâœ… Download started!\")\n",
        "    \n",
        "    print(\"\\nğŸ’» Usage:\")\n",
        "    print(\"```python\")\n",
        "    print(\"from ultralytics import YOLO\")\n",
        "    print(\"model = YOLO('combined_all_defects_best.pt')\")\n",
        "    print(\"results = model('image.jpg')\")\n",
        "    print(\"results[0].show()  # Shows all 3 defect types!\")\n",
        "    print(\"```\")\n",
        "    print(\"=\" * 80)\n",
        "else:\n",
        "    print(\"âŒ Model not found\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 9ï¸âƒ£ Visualize Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "import glob\n",
        "\n",
        "results_dir = f\"{CONFIG['project']}/{CONFIG['name']}\"\n",
        "\n",
        "print(\"ğŸ“ˆ Training Results:\\n\")\n",
        "print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "# Results plot\n",
        "if os.path.exists(f\"{results_dir}/results.png\"):\n",
        "    print(\"ğŸ“Š Training Curves:\\n\")\n",
        "    display(Image(filename=f\"{results_dir}/results.png\", width=1000))\n",
        "\n",
        "# Confusion matrix\n",
        "if os.path.exists(f\"{results_dir}/confusion_matrix.png\"):\n",
        "    print(\"\\nğŸ¯ Confusion Matrix:\\n\")\n",
        "    display(Image(filename=f\"{results_dir}/confusion_matrix.png\", width=800))\n",
        "\n",
        "# F1 curve\n",
        "if os.path.exists(f\"{results_dir}/F1_curve.png\"):\n",
        "    print(\"\\nğŸ“ˆ F1-Confidence Curve:\\n\")\n",
        "    display(Image(filename=f\"{results_dir}/F1_curve.png\", width=800))\n",
        "\n",
        "# Validation predictions\n",
        "val_images = sorted(glob.glob(f\"{results_dir}/val_batch*_pred.jpg\"))\n",
        "if val_images:\n",
        "    print(\"\\nğŸ” Validation Predictions:\\n\")\n",
        "    for img in val_images[:2]:\n",
        "        display(Image(filename=img, width=1000))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ğŸ“ Summary & Next Steps\n",
        "\n",
        "### âœ… Training Complete!\n",
        "\n",
        "You now have `combined_all_defects_best.pt` that detects:\n",
        "- ğŸ”´ **Crack** (class 0)\n",
        "- ğŸ§± **Spalling** (class 1)\n",
        "- ğŸ”© **Exposed Rebar** (class 2)\n",
        "\n",
        "### ğŸ“¥ Model Downloaded!\n",
        "\n",
        "The model has been automatically downloaded to your computer.\n",
        "\n",
        "### ğŸš€ Next Steps:\n",
        "\n",
        "1. **Upload to your project**: Place `combined_all_defects_best.pt` in your demo folder\n",
        "2. **Rename** (optional): Rename to `best.pt` to replace your current model\n",
        "3. **Update webapp**: Your `finalwebapp.py` will now detect all 3 defect types!\n",
        "\n",
        "### ğŸ’» Quick Test:\n",
        "\n",
        "```python\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load your combined model\n",
        "model = YOLO('combined_all_defects_best.pt')\n",
        "\n",
        "# Test on an image\n",
        "results = model('test_image.jpg')\n",
        "\n",
        "# Show results\n",
        "results[0].show()\n",
        "\n",
        "# Get detections\n",
        "for box in results[0].boxes:\n",
        "    cls = int(box.cls[0])\n",
        "    names = {0: 'crack', 1: 'spalling', 2: 'exposed_rebar'}\n",
        "    conf = float(box.conf[0])\n",
        "    print(f\"{names[cls]}: {conf:.2%}\")\n",
        "```\n",
        "\n",
        "### ğŸ¯ Model Performance:\n",
        "\n",
        "Check the visualizations above to see:\n",
        "- Training curves (loss decreasing, mAP increasing)\n",
        "- Confusion matrix (which classes it confuses)\n",
        "- Validation predictions (actual detections)\n",
        "\n",
        "---\n",
        "\n",
        "**One model for everything! ğŸ¯**\n",
        "\n",
        "Replace your current `best.pt` with this combined model and your webapp will detect cracks, spalling, AND exposed rebar!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
